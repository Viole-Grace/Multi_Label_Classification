{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic Comment Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F9JAmfVZEeM",
        "colab_type": "code",
        "outputId": "409e0efe-04cf-4d8c-fd2d-583498cee096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HFgUsvrZIwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7L4IAyzbKgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a20128f0-89a3-4aa6-cae0-0fae809fc54d"
      },
      "source": [
        "df = pd.read_csv('scraped data.csv')\n",
        "print(df.shape)\n",
        "\n",
        "#remove null values\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df.isnull().sum()\n",
        "print(df.columns)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(159571, 8)\n",
            "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
            "       'insult', 'identity_hate'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO8Cy9X-bh8X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "5e9185ca-808d-4d2c-e0d1-c33cfd872803"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "5  00025465d4725e87  ...             0\n",
              "6  0002bcb3da6cb337  ...             0\n",
              "7  00031b1e95af7921  ...             0\n",
              "8  00037261f536c51d  ...             0\n",
              "9  00040093b2687caa  ...             0\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bXE8JiCbo8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cec3ba67-07e5-440d-d655-61fcd0b34fa5"
      },
      "source": [
        "#check GPU Availability\n",
        "import tensorflow as tf\n",
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqdnhKG7byxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.describe()\n",
        "\n",
        "classes = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
        "targets = df[classes].values\n",
        "\n",
        "#perform feature engineering using GloVe Embeddings\n",
        "\n",
        "embedding_file_path = 'drive/My Drive/glove.6B.100d.txt' #GloVe embedding file. Almost 350MB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3m9xV5yjs3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9da1a32b-46db-49cc-95d0-5e5c131991e5"
      },
      "source": [
        "targets[:2]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58mW40U6dGrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.layers import Input, Embedding, GRU, Dense, Activation, Dropout, CuDNNGRU\n",
        "from tensorflow.keras.layers import RNN, concatenate\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalAveragePooling1D, GlobalMaxPool1D\n",
        "\n",
        "from tensorflow.keras import initializers, optimizers\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8fFU6Dbe9bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = df['comment_text'].fillna(' ').str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5fMBEZoeJjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features, embed_size, maxlen = 100000, 100, 150\n",
        "tokenizer = Tokenizer(max_features)\n",
        "\n",
        "tokenizer.fit_on_texts(list(features))\n",
        "sentences = tokenizer.texts_to_sequences(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gggU4SO9fVz4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "f7f1b93d-ba17-4a8a-9a43-3e4976c8e495"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[688,\n",
              " 75,\n",
              " 1,\n",
              " 126,\n",
              " 130,\n",
              " 177,\n",
              " 29,\n",
              " 672,\n",
              " 4511,\n",
              " 12052,\n",
              " 1116,\n",
              " 86,\n",
              " 331,\n",
              " 51,\n",
              " 2278,\n",
              " 11448,\n",
              " 50,\n",
              " 6864,\n",
              " 15,\n",
              " 60,\n",
              " 2756,\n",
              " 148,\n",
              " 7,\n",
              " 2937,\n",
              " 34,\n",
              " 117,\n",
              " 1221,\n",
              " 15190,\n",
              " 2825,\n",
              " 4,\n",
              " 45,\n",
              " 59,\n",
              " 244,\n",
              " 1,\n",
              " 365,\n",
              " 31,\n",
              " 1,\n",
              " 38,\n",
              " 27,\n",
              " 143,\n",
              " 73,\n",
              " 3462,\n",
              " 89,\n",
              " 3085,\n",
              " 4583,\n",
              " 2273,\n",
              " 985]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkuZW1Offa4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_features = pad_sequences(sentences, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQDt4hwXfkoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coefs(word, *arr): \n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "#costly operations, do it at your own risk\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(embedding_file_path))\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9xXwCJZhF3a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "27621522-4831-4764-a800-ee2377241a21"
      },
      "source": [
        "#build the Deep Learning model\n",
        "\n",
        "orig_input = Input(shape=(maxlen,)) #series\n",
        "embed_layer = Embedding(max_features, embed_size, weights = [embedding_matrix], trainable=False)(orig_input)\n",
        "bi_layer = Bidirectional(CuDNNGRU(128, return_sequences=True))(embed_layer)\n",
        "avg_pool = GlobalAveragePooling1D()(bi_layer)\n",
        "max_pool = GlobalMaxPool1D()(bi_layer)\n",
        "\n",
        "conc_layer = concatenate([avg_pool, max_pool])\n",
        "prediction_layer = Dense(6, activation='sigmoid')(conc_layer)\n",
        "\n",
        "model = Model(inputs=orig_input, outputs=prediction_layer)\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizers.Adam(clipnorm=1.))\n",
        "\n",
        "print(model.summary())\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 150, 100)     10000000    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 150, 256)     176640      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 256)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 256)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 512)          0           global_average_pooling1d[0][0]   \n",
            "                                                                 global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 6)            3078        concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 10,179,718\n",
            "Trainable params: 179,718\n",
            "Non-trainable params: 10,000,000\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DupBe_Odiwdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saved_model_file = 'best_acc_toxic_weights.hdf5'\n",
        "ckpt = ModelCheckpoint(saved_model_file, monitor='val_acc', save_best_only=True, save_weights_only=True, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh5e1kKkjHYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "e7723d39-4657-4c43-e912-a764c32d24cd"
      },
      "source": [
        "bs, ep = 32, 5\n",
        "\n",
        "model.fit(padded_features, targets, validation_split=0.3, epochs=ep, batch_size=bs, callbacks=[ckpt])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 111699 samples, validate on 47872 samples\n",
            "Epoch 1/5\n",
            "111699/111699 [==============================] - 70s 625us/sample - loss: 0.0597 - acc: 0.9790 - val_loss: 0.0499 - val_acc: 0.9817\n",
            "Epoch 2/5\n",
            "111699/111699 [==============================] - 58s 522us/sample - loss: 0.0463 - acc: 0.9826 - val_loss: 0.0480 - val_acc: 0.9822\n",
            "Epoch 3/5\n",
            "111699/111699 [==============================] - 58s 522us/sample - loss: 0.0421 - acc: 0.9841 - val_loss: 0.0466 - val_acc: 0.9826\n",
            "Epoch 4/5\n",
            "111699/111699 [==============================] - 58s 517us/sample - loss: 0.0384 - acc: 0.9853 - val_loss: 0.0473 - val_acc: 0.9827\n",
            "Epoch 5/5\n",
            "111699/111699 [==============================] - 58s 518us/sample - loss: 0.0346 - acc: 0.9867 - val_loss: 0.0477 - val_acc: 0.9824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbae53c1128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBqG6h6syt8O",
        "colab_type": "code",
        "outputId": "b82539f5-154d-41d3-be8c-4bebec7966b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L6XSbzwjYYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('tokenizer.pickle','wb') as f:\n",
        "    pickle.dump(tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "#save tokenizer to fit on texts during testing."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLMFwZCflWqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save embedding matrix, model\n",
        "with open('embedding_matrix.pickle', 'wb') as f:\n",
        "    pickle.dump(embedding_matrix,f,protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "model.save('Toxic_Comments_Model.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLwUNksPl5ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#call a testing / prediction line.\n",
        "\n",
        "def get_coefs(word, *arr): \n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def test_prediction(sent, tokenizer='tokenizer.pickle', embedding_matrix='embedding_matrix.pickle', model='Toxic_Comments_Model.model'):\n",
        "\n",
        "    \n",
        "    if len(sent) == 0:\n",
        "        print(\"No input entered - please enter a valid input\")\n",
        "        return\n",
        "        \n",
        "    import numpy as np\n",
        "    import nltk\n",
        "    import os\n",
        "\n",
        "    import pickle\n",
        "\n",
        "    from tensorflow.keras.models import Model\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "    from tensorflow.keras.models import load_model\n",
        "\n",
        "    #do all the preprocessing you did earlier\n",
        "\n",
        "    max_features, embed_size, maxlen = 100000, 100, 150\n",
        "\n",
        "    tokenizer_file = open(tokenizer,'rb')\n",
        "    tokenizer = pickle.load(tokenizer_file)\n",
        "    tokenizer_file.close()\n",
        "\n",
        "    features = sent.lower()\n",
        "\n",
        "    sentences = tokenizer.texts_to_sequences([features])\n",
        "\n",
        "    padded_features = pad_sequences(sentences, maxlen=maxlen) #features\n",
        "\n",
        "    #run model.predict()\n",
        "\n",
        "    model = load_model(model) #load the trained model\n",
        "    label_list = model.predict(padded_features)\n",
        "    print(label_list)\n",
        "\n",
        "    predict_labels = []\n",
        "    for item in label_list[0]:\n",
        "        predict_labels.append(int(round(item)))\n",
        "    \n",
        "    classes = [\"Toxic\",\", Severely Toxic\",\", Obscene\",\", a Threat\",\", an Insult\",\", Identity Hate\"]\n",
        "\n",
        "    print(\"The sentence : '{}', is classified as : \\n\".format(sent))\n",
        "    for i in range(len(classes)):\n",
        "        if predict_labels[i] == 1:\n",
        "            print(classes[i],end=\" \")\n",
        "\n",
        "    return predict_labels, label_list[0]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XxT1RLeOPXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3870232c-bafd-4c38-c03a-43517119ee6e"
      },
      "source": [
        "proba, labels = test_prediction('I am hungry, you bitch. My hatred for you knows no bounds')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.98371685 0.02448905 0.9282901  0.00607422 0.6033909  0.01199554]]\n",
            "The sentence : 'I am hungry, you bitch. My hatred for you knows no bounds', is classified as : \n",
            "\n",
            "Toxic , Obscene , an Insult "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}